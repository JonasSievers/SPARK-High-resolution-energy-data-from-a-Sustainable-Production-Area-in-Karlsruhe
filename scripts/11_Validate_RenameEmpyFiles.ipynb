{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc84139f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWe systematically scanned all per-file statistics to detect series whose core and quantile metrics are entirely zero or NaN. \\nThese cases were registered in a canonical list (machine, measurement, year) and the corresponding originals were replaced\\nby explicit *_EMPTY placeholder files (single timestamp–value row), with originals safely backed up.\\nIf a measurement folder contained only placeholders, it was renamed to _EMPTY for immediate visibility.\\nEvery action (backup, rewrite, rename, skip) was logged for auditability. This ensures downstream pipelines remain stable,\\ncomparisons are fair, and data quality issues are transparent and reproducible.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "We systematically scanned all per-file statistics to detect series whose core and quantile metrics are entirely zero or NaN. \n",
    "These cases were registered in a canonical list (machine, measurement, year) and the corresponding originals were replaced\n",
    "by explicit *_EMPTY placeholder files (single timestamp–value row), with originals safely backed up.\n",
    "If a measurement folder contained only placeholders, it was renamed to _EMPTY for immediate visibility.\n",
    "Every action (backup, rewrite, rename, skip) was logged for auditability. This ensures downstream pipelines remain stable,\n",
    "comparisons are fair, and data quality issues are transparent and reproducible.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c0df6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>all_ZoN</th>\n",
       "      <th>core_ZoN</th>\n",
       "      <th>mm_ZoN</th>\n",
       "      <th>q_ZoN</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>q01</th>\n",
       "      <th>q05</th>\n",
       "      <th>q25</th>\n",
       "      <th>q50</th>\n",
       "      <th>q75</th>\n",
       "      <th>q95</th>\n",
       "      <th>q99</th>\n",
       "      <th>flag_label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Freq_2018</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>49.83</td>\n",
       "      <td>50.13000</td>\n",
       "      <td>49.988551</td>\n",
       "      <td>0.021301</td>\n",
       "      <td>49.940000</td>\n",
       "      <td>49.96000</td>\n",
       "      <td>49.97000</td>\n",
       "      <td>49.99000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.02000</td>\n",
       "      <td>50.04000</td>\n",
       "      <td>none</td>\n",
       "      <td>validation_results\\EPI_ChipPress\\Freq\\2018_Fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Freq_2019</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>49.79</td>\n",
       "      <td>50.16000</td>\n",
       "      <td>49.988537</td>\n",
       "      <td>0.020415</td>\n",
       "      <td>49.940000</td>\n",
       "      <td>49.96000</td>\n",
       "      <td>49.98000</td>\n",
       "      <td>49.99000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.02000</td>\n",
       "      <td>50.04000</td>\n",
       "      <td>none</td>\n",
       "      <td>validation_results\\EPI_ChipPress\\Freq\\2019_Fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Freq_2020</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>49.81</td>\n",
       "      <td>50.13000</td>\n",
       "      <td>49.988533</td>\n",
       "      <td>0.019694</td>\n",
       "      <td>49.940000</td>\n",
       "      <td>49.96000</td>\n",
       "      <td>49.98000</td>\n",
       "      <td>49.99000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.02000</td>\n",
       "      <td>50.04000</td>\n",
       "      <td>none</td>\n",
       "      <td>validation_results\\EPI_ChipPress\\Freq\\2020_Fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Freq_2021</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>49.75</td>\n",
       "      <td>50.14000</td>\n",
       "      <td>49.988628</td>\n",
       "      <td>0.020425</td>\n",
       "      <td>49.940000</td>\n",
       "      <td>49.96000</td>\n",
       "      <td>49.98000</td>\n",
       "      <td>49.99000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.02000</td>\n",
       "      <td>50.04000</td>\n",
       "      <td>none</td>\n",
       "      <td>validation_results\\EPI_ChipPress\\Freq\\2021_Fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Freq_2022</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>49.83</td>\n",
       "      <td>50.12000</td>\n",
       "      <td>49.988549</td>\n",
       "      <td>0.020896</td>\n",
       "      <td>49.930000</td>\n",
       "      <td>49.95000</td>\n",
       "      <td>49.97000</td>\n",
       "      <td>49.99000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.02000</td>\n",
       "      <td>50.04000</td>\n",
       "      <td>none</td>\n",
       "      <td>validation_results\\EPI_ChipPress\\Freq\\2022_Fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14645</th>\n",
       "      <td>U3_RMS_fund_2024</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>243.03232</td>\n",
       "      <td>237.193991</td>\n",
       "      <td>3.180266</td>\n",
       "      <td>233.038798</td>\n",
       "      <td>234.03572</td>\n",
       "      <td>235.88918</td>\n",
       "      <td>237.32402</td>\n",
       "      <td>238.58334</td>\n",
       "      <td>240.18796</td>\n",
       "      <td>241.04272</td>\n",
       "      <td>none</td>\n",
       "      <td>validation_results\\TEC_MV2400R\\U3_RMS_fund\\202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14646</th>\n",
       "      <td>U_line_avg_2024</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>419.88500</td>\n",
       "      <td>410.032508</td>\n",
       "      <td>4.702562</td>\n",
       "      <td>402.803530</td>\n",
       "      <td>404.52000</td>\n",
       "      <td>407.80743</td>\n",
       "      <td>410.28070</td>\n",
       "      <td>412.39017</td>\n",
       "      <td>415.10425</td>\n",
       "      <td>416.56128</td>\n",
       "      <td>none</td>\n",
       "      <td>validation_results\\TEC_MV2400R\\U_line_avg\\2024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14647</th>\n",
       "      <td>U_line_avg_f_2024</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>419.55536</td>\n",
       "      <td>409.808778</td>\n",
       "      <td>6.700745</td>\n",
       "      <td>402.667820</td>\n",
       "      <td>404.41630</td>\n",
       "      <td>407.62872</td>\n",
       "      <td>410.10560</td>\n",
       "      <td>412.23367</td>\n",
       "      <td>414.87683</td>\n",
       "      <td>416.27840</td>\n",
       "      <td>none</td>\n",
       "      <td>validation_results\\TEC_MV2400R\\U_line_avg_f\\20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14648</th>\n",
       "      <td>U_phase_avg_2024</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>278.76743</td>\n",
       "      <td>236.744303</td>\n",
       "      <td>2.719823</td>\n",
       "      <td>232.577380</td>\n",
       "      <td>233.56544</td>\n",
       "      <td>235.45988</td>\n",
       "      <td>236.88562</td>\n",
       "      <td>238.10399</td>\n",
       "      <td>239.67280</td>\n",
       "      <td>240.51324</td>\n",
       "      <td>none</td>\n",
       "      <td>validation_results\\TEC_MV2400R\\U_phase_avg\\202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14649</th>\n",
       "      <td>U_phase_avg_f_2024</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>242.23042</td>\n",
       "      <td>236.603081</td>\n",
       "      <td>3.873720</td>\n",
       "      <td>232.480620</td>\n",
       "      <td>233.48996</td>\n",
       "      <td>235.34450</td>\n",
       "      <td>236.77454</td>\n",
       "      <td>238.00317</td>\n",
       "      <td>239.52924</td>\n",
       "      <td>240.33861</td>\n",
       "      <td>none</td>\n",
       "      <td>validation_results\\TEC_MV2400R\\U_phase_avg_f\\2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14650 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name  all_ZoN  core_ZoN  mm_ZoN  q_ZoN    min        max  \\\n",
       "0               Freq_2018    False     False   False  False  49.83   50.13000   \n",
       "1               Freq_2019    False     False   False  False  49.79   50.16000   \n",
       "2               Freq_2020    False     False   False  False  49.81   50.13000   \n",
       "3               Freq_2021    False     False   False  False  49.75   50.14000   \n",
       "4               Freq_2022    False     False   False  False  49.83   50.12000   \n",
       "...                   ...      ...       ...     ...    ...    ...        ...   \n",
       "14645    U3_RMS_fund_2024    False     False   False  False   0.00  243.03232   \n",
       "14646     U_line_avg_2024    False     False   False  False   0.00  419.88500   \n",
       "14647   U_line_avg_f_2024    False     False   False  False   0.00  419.55536   \n",
       "14648    U_phase_avg_2024    False     False   False  False   0.00  278.76743   \n",
       "14649  U_phase_avg_f_2024    False     False   False  False   0.00  242.23042   \n",
       "\n",
       "             mean       std         q01        q05        q25        q50  \\\n",
       "0       49.988551  0.021301   49.940000   49.96000   49.97000   49.99000   \n",
       "1       49.988537  0.020415   49.940000   49.96000   49.98000   49.99000   \n",
       "2       49.988533  0.019694   49.940000   49.96000   49.98000   49.99000   \n",
       "3       49.988628  0.020425   49.940000   49.96000   49.98000   49.99000   \n",
       "4       49.988549  0.020896   49.930000   49.95000   49.97000   49.99000   \n",
       "...           ...       ...         ...        ...        ...        ...   \n",
       "14645  237.193991  3.180266  233.038798  234.03572  235.88918  237.32402   \n",
       "14646  410.032508  4.702562  402.803530  404.52000  407.80743  410.28070   \n",
       "14647  409.808778  6.700745  402.667820  404.41630  407.62872  410.10560   \n",
       "14648  236.744303  2.719823  232.577380  233.56544  235.45988  236.88562   \n",
       "14649  236.603081  3.873720  232.480620  233.48996  235.34450  236.77454   \n",
       "\n",
       "             q75        q95        q99 flag_label  \\\n",
       "0       50.00000   50.02000   50.04000       none   \n",
       "1       50.00000   50.02000   50.04000       none   \n",
       "2       50.00000   50.02000   50.04000       none   \n",
       "3       50.00000   50.02000   50.04000       none   \n",
       "4       50.00000   50.02000   50.04000       none   \n",
       "...          ...        ...        ...        ...   \n",
       "14645  238.58334  240.18796  241.04272       none   \n",
       "14646  412.39017  415.10425  416.56128       none   \n",
       "14647  412.23367  414.87683  416.27840       none   \n",
       "14648  238.10399  239.67280  240.51324       none   \n",
       "14649  238.00317  239.52924  240.33861       none   \n",
       "\n",
       "                                                    file  \n",
       "0      validation_results\\EPI_ChipPress\\Freq\\2018_Fre...  \n",
       "1      validation_results\\EPI_ChipPress\\Freq\\2019_Fre...  \n",
       "2      validation_results\\EPI_ChipPress\\Freq\\2020_Fre...  \n",
       "3      validation_results\\EPI_ChipPress\\Freq\\2021_Fre...  \n",
       "4      validation_results\\EPI_ChipPress\\Freq\\2022_Fre...  \n",
       "...                                                  ...  \n",
       "14645  validation_results\\TEC_MV2400R\\U3_RMS_fund\\202...  \n",
       "14646  validation_results\\TEC_MV2400R\\U_line_avg\\2024...  \n",
       "14647  validation_results\\TEC_MV2400R\\U_line_avg_f\\20...  \n",
       "14648  validation_results\\TEC_MV2400R\\U_phase_avg\\202...  \n",
       "14649  validation_results\\TEC_MV2400R\\U_phase_avg_f\\2...  \n",
       "\n",
       "[14650 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "class ZeroNanChecker:\n",
    "    COLS = [\"file_path\",\"min\",\"max\",\"mean\",\"std\",\"q01\",\"q05\",\"q25\",\"q50\",\"q75\",\"q95\",\"q99\"]\n",
    "\n",
    "    def scan(self, root=\"validation_results\", test=None):\n",
    "        files = sorted(Path(root).rglob(\"*_stats.csv\"))\n",
    "        if test: files = files[:int(test)]\n",
    "        rows = []\n",
    "        for f in files:\n",
    "            try:\n",
    "                df = pd.read_csv(f)\n",
    "            except Exception as e:\n",
    "                rows.append(self.empty_row(str(f), e))\n",
    "                continue\n",
    "\n",
    "            for c in self.COLS:\n",
    "                if c not in df: df[c] = np.nan\n",
    "            num_cols = [c for c in self.COLS if c != \"file_path\"]\n",
    "            df[num_cols] = df[num_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "            for _, r in df.iterrows():\n",
    "                rows.append(self.eval_row(f, r))\n",
    "\n",
    "        out = pd.DataFrame(rows)\n",
    "        self.save(out)\n",
    "        display(out)\n",
    "        return out\n",
    "\n",
    "    def eval_row(self, f, r):\n",
    "        z = lambda x: (pd.isna(x) or x == 0)\n",
    "\n",
    "        all_stats = [r.get(c) for c in self.COLS if c != \"file_path\"]\n",
    "        core_stats = [r.get(\"min\"), r.get(\"max\"), r.get(\"mean\"), r.get(\"std\")]\n",
    "        quantiles = [r.get(\"q01\"), r.get(\"q05\"), r.get(\"q25\"), r.get(\"q50\"), r.get(\"q75\"), r.get(\"q95\"), r.get(\"q99\")]\n",
    "        mn, mx = r.get(\"min\"), r.get(\"max\")\n",
    "\n",
    "        all_flag = all(z(v) for v in all_stats)\n",
    "        core_flag = all(z(v) for v in core_stats)\n",
    "        mm_flag = z(mn) and z(mx)\n",
    "        q_flag = all(z(v) for v in quantiles)\n",
    "\n",
    "        if all_flag: label = \"all_stats_zero_or_nan\"\n",
    "        elif core_flag: label = \"core_stats_zero_or_nan\"\n",
    "        elif mm_flag: label = \"min_max_zero_or_nan\"\n",
    "        elif q_flag: label = \"quantiles_zero_or_nan\"\n",
    "        else: label = \"none\"\n",
    "\n",
    "        name = self.make_name(f)\n",
    "\n",
    "        return {\n",
    "            \"name\": name,\n",
    "            \"all_ZoN\": bool(all_flag),\n",
    "            \"core_ZoN\": bool(core_flag),\n",
    "            \"mm_ZoN\": bool(mm_flag),\n",
    "            \"q_ZoN\": bool(q_flag),\n",
    "            \"min\": mn, \"max\": mx, \"mean\": r.get(\"mean\"), \"std\": r.get(\"std\"),\n",
    "            \"q01\": r.get(\"q01\"), \"q05\": r.get(\"q05\"), \"q25\": r.get(\"q25\"),\n",
    "            \"q50\": r.get(\"q50\"), \"q75\": r.get(\"q75\"), \"q95\": r.get(\"q95\"), \"q99\": r.get(\"q99\"),\n",
    "            \"flag_label\": label,\n",
    "            \"file\": str(f)\n",
    "        }\n",
    "\n",
    "    def make_name(self, fpath):\n",
    "        parts = fpath.parts\n",
    "        if len(parts) >= 3:\n",
    "            measurement = parts[-2]\n",
    "            m = re.search(r\"(\\d{4})\", parts[-1])\n",
    "            if m:\n",
    "                return f\"{measurement}_{m.group(1)}\"\n",
    "        return parts[-1]\n",
    "\n",
    "    def empty_row(self, f, error):\n",
    "        return {\n",
    "            \"name\": self.make_name(Path(f)),\n",
    "            \"all_ZoN\": np.nan, \"core_ZoN\": np.nan, \"mm_ZoN\": np.nan, \"q_ZoN\": np.nan,\n",
    "            **{c: np.nan for c in self.COLS if c != \"file_path\"},\n",
    "            \"flag_label\": \"error\",\n",
    "            \"file\": f,\n",
    "            \"error\": error\n",
    "        }\n",
    "\n",
    "    def save(self, df, path=\"all_zero_or_nan_report.csv\"):\n",
    "        order = [\n",
    "            \"name\", \"all_ZoN\", \"core_ZoN\", \"mm_ZoN\", \"q_ZoN\",\n",
    "            \"min\",\"max\",\"mean\",\"std\",\"q01\",\"q05\",\"q25\",\"q50\",\"q75\",\"q95\",\"q99\",\n",
    "            \"flag_label\",\"file\"\n",
    "        ]\n",
    "        cols = [c for c in order if c in df.columns]\n",
    "        df[cols].to_csv(path, index=False)\n",
    "\n",
    "    def plot_row(self, results_df: pd.DataFrame, idx: int, data_root=\"dataset_clean\"):\n",
    "        stats_path = Path(results_df.loc[idx, \"file\"])\n",
    "        if not stats_path.exists():\n",
    "            raise FileNotFoundError(f\"Stats file not found: {stats_path}\")\n",
    "\n",
    "        data_path = None\n",
    "        try:\n",
    "            sdf = pd.read_csv(stats_path, usecols=[\"file_path\"])\n",
    "            if len(sdf) > 0 and pd.notna(sdf.loc[0, \"file_path\"]):\n",
    "                data_path = Path(str(sdf.loc[0, \"file_path\"]))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        if data_path is None:\n",
    "            rel = stats_path.as_posix()\n",
    "            rel = re.sub(r\"^validation_results\", str(data_root), rel)\n",
    "            rel = re.sub(r\"_stats\\.csv$\", \".csv.xz\", rel)\n",
    "            data_path = Path(rel)\n",
    "\n",
    "        if not data_path.exists():\n",
    "            raise FileNotFoundError(f\"Data file not found (resolved): {data_path}\")\n",
    "\n",
    "        df = pd.read_csv(data_path)\n",
    "\n",
    "        ts_cols = [c for c in df.columns if str(c).lower() in {\"ts\",\"time\",\"timestamp\",\"datetime\",\"date\",\"datetimes\"}]\n",
    "        if ts_cols:\n",
    "            tc = ts_cols[0]\n",
    "            df[tc] = pd.to_datetime(df[tc], errors=\"coerce\", utc=True)\n",
    "            df = df.set_index(tc).sort_index()\n",
    "\n",
    "        num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        if not num_cols:\n",
    "            raise ValueError(f\"No numeric columns to plot in {data_path}\")\n",
    "\n",
    "        ycol = num_cols[0]\n",
    "        plt.figure()\n",
    "        df[ycol].plot(title=f\"{results_df.loc[idx,'name']} — {ycol}\")\n",
    "        plt.xlabel(\"time\" if ts_cols else \"row\")\n",
    "        plt.ylabel(ycol)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        return df, data_path\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    checker = ZeroNanChecker()\n",
    "    res = checker.scan(test=None)  # set to None for full run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de523e35",
   "metadata": {},
   "source": [
    "### Create Registry of Files that are all empty and should be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dafc36cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registry written:\n",
      "- dataset_clean\\00meta_data\\01removed_files_registry.csv\n",
      "\n",
      "1352 entries marked as all-zero-or-nan.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from pathlib import PurePath, Path\n",
    "import pandas as pd\n",
    "\n",
    "# === CONFIG ===\n",
    "REPORT_CSV = r\"dataset_clean/00meta_data/01all_zero_or_nan_report.csv\"\n",
    "# Where your real data files live (NOT the validation_results dir).\n",
    "# Example structure: <DATA_ROOT>/<machine>/<measurement>/<year>_<measurement>.csv.xz\n",
    "DATA_ROOT = Path(r\"D:\\energy_dataset\")  # <-- change this\n",
    "\n",
    "REGISTRY_CSV   = Path(\"dataset_clean/00meta_data/01removed_files_registry.csv\")\n",
    "\n",
    "# === LOAD & FILTER ===\n",
    "val_df = pd.read_csv(REPORT_CSV)\n",
    "all_ZoN_df = val_df[val_df[\"all_ZoN\"] == True].copy()\n",
    "\n",
    "# === HELPERS ===\n",
    "year_tail_pat = re.compile(r\"^(?P<meas>.+)_(?P<year>\\d{4})$\")\n",
    "\n",
    "def parse_name_field(s: str):\n",
    "    \"\"\"\n",
    "    'U12_h31_2018' -> (measurement='U12_h31', year='2018')\n",
    "    Works even if measurement contains underscores, as year must be 4 digits at end.\n",
    "    \"\"\"\n",
    "    m = year_tail_pat.match(str(s))\n",
    "    if m:\n",
    "        return m.group(\"meas\"), m.group(\"year\")\n",
    "    return None, None\n",
    "\n",
    "def parse_from_validation_path(p: str):\n",
    "    \"\"\"\n",
    "    Example: 'validation_results\\\\EPI_ChipPress\\\\U12_h31\\\\2019_U12_h31_stats.csv'\n",
    "    -> machine='EPI_ChipPress', measurement='U12_h31'\n",
    "    We do NOT trust the filename for the year here (prefer 'name' column’s year).\n",
    "    \"\"\"\n",
    "    parts = PurePath(p).parts\n",
    "    # Find 'validation_results' and take the next two components as machine/measurement if present\n",
    "    try:\n",
    "        vr_idx = [i for i, part in enumerate(parts) if part.lower() == \"validation_results\"][0]\n",
    "        machine = parts[vr_idx + 1] if len(parts) > vr_idx + 1 else None\n",
    "        measurement = parts[vr_idx + 2] if len(parts) > vr_idx + 2 else None\n",
    "    except (IndexError, ValueError):\n",
    "        machine, measurement = None, None\n",
    "    return machine, measurement\n",
    "\n",
    "def expected_data_path(data_root: Path, machine: str, measurement: str, year: str) -> Path | None:\n",
    "    \"\"\"\n",
    "    Build the expected data file path under your real dataset root.\n",
    "    \"\"\"\n",
    "    if not all([data_root, machine, measurement, year]):\n",
    "        return None\n",
    "    # Adjust this if your naming differs (e.g., lowercase, hyphens, etc.)\n",
    "    return data_root / machine / measurement / f\"{year}_{measurement}.csv.xz\"\n",
    "\n",
    "# === BUILD REGISTRY ===\n",
    "rows = []\n",
    "for _, r in all_ZoN_df.iterrows():\n",
    "    meas_from_name, year = parse_name_field(r.get(\"name\", \"\"))\n",
    "    machine_from_path, meas_from_path = parse_from_validation_path(r.get(\"file\", \"\"))\n",
    "\n",
    "    # Prefer path-derived machine; prefer name-derived measurement (more reliable with year parsing)\n",
    "    machine = machine_from_path\n",
    "    measurement = meas_from_name or meas_from_path\n",
    "\n",
    "    # Fall back if name didn’t parse (rare)\n",
    "    if (measurement is None) and (meas_from_path is not None):\n",
    "        # try to remove a leading year + underscore pattern if present\n",
    "        m2 = re.match(r\"^\\d{4}_(.+)$\", meas_from_path)\n",
    "        measurement = m2.group(1) if m2 else meas_from_path\n",
    "\n",
    "    data_path = expected_data_path(DATA_ROOT, machine, measurement, year)\n",
    "\n",
    "    rows.append({\n",
    "        \"machine\": machine,\n",
    "        \"measurement\": measurement,\n",
    "        \"year\": year,\n",
    "        \"reason\": \"all_zero_or_nan\",                      # stable canonical label\n",
    "        \"flag_label\": r.get(\"flag_label\", \"\"),            # keep original label for traceability\n",
    "        \"validation_report_file\": r.get(\"file\", \"\"),      # where the decision came from\n",
    "        \"expected_data_file\": str(data_path) if data_path else None,\n",
    "        \"all_ZoN\": True,\n",
    "        # optional stats for auditability (useful in docs)\n",
    "        \"min\": r.get(\"min\", None),\n",
    "        \"max\": r.get(\"max\", None),\n",
    "        \"mean\": r.get(\"mean\", None),\n",
    "        \"std\": r.get(\"std\", None),\n",
    "        \"q01\": r.get(\"q01\", None),\n",
    "        \"q05\": r.get(\"q05\", None),\n",
    "        \"q25\": r.get(\"q25\", None),\n",
    "        \"q50\": r.get(\"q50\", None),\n",
    "        \"q75\": r.get(\"q75\", None),\n",
    "        \"q95\": r.get(\"q95\", None),\n",
    "        \"q99\": r.get(\"q99\", None),\n",
    "    })\n",
    "\n",
    "registry = pd.DataFrame(rows)\n",
    "\n",
    "# Normalize / sanity checks\n",
    "registry[\"machine\"] = registry[\"machine\"].astype(\"string\")\n",
    "registry[\"measurement\"] = registry[\"measurement\"].astype(\"string\")\n",
    "registry[\"year\"] = registry[\"year\"].astype(\"string\")\n",
    "\n",
    "# Drop obvious malformed rows (no machine or measurement or year)\n",
    "registry = registry.dropna(subset=[\"machine\", \"measurement\", \"year\"]).reset_index(drop=True)\n",
    "\n",
    "# De-duplicate (idempotent reruns)\n",
    "registry = registry.drop_duplicates(subset=[\"machine\", \"measurement\", \"year\"]).reset_index(drop=True)\n",
    "\n",
    "# === SAVE REGISTRY ===\n",
    "registry.to_csv(REGISTRY_CSV, index=False)\n",
    "\n",
    "\n",
    "print(f\"Registry written:\\n- {REGISTRY_CSV}\\n\")\n",
    "print(f\"{len(registry)} entries marked as all-zero-or-nan.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0da0449",
   "metadata": {},
   "source": [
    "### Delete and Replace empty files with Short and REMANED Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68d9a3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>machine</th>\n",
       "      <th>measurement</th>\n",
       "      <th>year</th>\n",
       "      <th>path</th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>missing_original</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U12_h31</td>\n",
       "      <td>2018</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U12_h31\\2018_U12_h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>backup_original</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U12_h31</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U12_h31\\2019_U12_h...</td>\n",
       "      <td>D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>write_empty_file</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U12_h31</td>\n",
       "      <td>2019</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U12_h31\\2019_U12_h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>backup_original</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h21</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h21\\2019_U1_h21...</td>\n",
       "      <td>D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>write_empty_file</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h21</td>\n",
       "      <td>2019</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h21\\2019_U1_h21...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>backup_original</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h21</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h21\\2022_U1_h21...</td>\n",
       "      <td>D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>write_empty_file</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h21</td>\n",
       "      <td>2022</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h21\\2022_U1_h21...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>backup_original</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h21</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h21\\2023_U1_h21...</td>\n",
       "      <td>D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>write_empty_file</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h21</td>\n",
       "      <td>2023</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h21\\2023_U1_h21...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>backup_original</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h23</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h23\\2023_U1_h23...</td>\n",
       "      <td>D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>write_empty_file</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h23</td>\n",
       "      <td>2023</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h23\\2023_U1_h23...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>backup_original</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h25</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h25\\2018_U1_h25...</td>\n",
       "      <td>D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>write_empty_file</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h25</td>\n",
       "      <td>2018</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h25\\2018_U1_h25...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>backup_original</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h25</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h25\\2019_U1_h25...</td>\n",
       "      <td>D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>write_empty_file</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h25</td>\n",
       "      <td>2019</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h25\\2019_U1_h25...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>backup_original</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h25</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h25\\2022_U1_h25...</td>\n",
       "      <td>D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>write_empty_file</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h25</td>\n",
       "      <td>2022</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h25\\2022_U1_h25...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>backup_original</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h25</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h25\\2023_U1_h25...</td>\n",
       "      <td>D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>write_empty_file</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h25</td>\n",
       "      <td>2023</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h25\\2023_U1_h25...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>backup_original</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h27</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h27\\2018_U1_h27...</td>\n",
       "      <td>D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              action        machine measurement  year  \\\n",
       "0   missing_original  EPI_ChipPress     U12_h31  2018   \n",
       "1    backup_original  EPI_ChipPress     U12_h31  2019   \n",
       "2   write_empty_file  EPI_ChipPress     U12_h31  2019   \n",
       "3    backup_original  EPI_ChipPress      U1_h21  2019   \n",
       "4   write_empty_file  EPI_ChipPress      U1_h21  2019   \n",
       "5    backup_original  EPI_ChipPress      U1_h21  2022   \n",
       "6   write_empty_file  EPI_ChipPress      U1_h21  2022   \n",
       "7    backup_original  EPI_ChipPress      U1_h21  2023   \n",
       "8   write_empty_file  EPI_ChipPress      U1_h21  2023   \n",
       "9    backup_original  EPI_ChipPress      U1_h23  2023   \n",
       "10  write_empty_file  EPI_ChipPress      U1_h23  2023   \n",
       "11   backup_original  EPI_ChipPress      U1_h25  2018   \n",
       "12  write_empty_file  EPI_ChipPress      U1_h25  2018   \n",
       "13   backup_original  EPI_ChipPress      U1_h25  2019   \n",
       "14  write_empty_file  EPI_ChipPress      U1_h25  2019   \n",
       "15   backup_original  EPI_ChipPress      U1_h25  2022   \n",
       "16  write_empty_file  EPI_ChipPress      U1_h25  2022   \n",
       "17   backup_original  EPI_ChipPress      U1_h25  2023   \n",
       "18  write_empty_file  EPI_ChipPress      U1_h25  2023   \n",
       "19   backup_original  EPI_ChipPress      U1_h27  2018   \n",
       "\n",
       "                                                 path  \\\n",
       "0   dataset_clean\\EPI_ChipPress\\U12_h31\\2018_U12_h...   \n",
       "1                                                 NaN   \n",
       "2   dataset_clean\\EPI_ChipPress\\U12_h31\\2019_U12_h...   \n",
       "3                                                 NaN   \n",
       "4   dataset_clean\\EPI_ChipPress\\U1_h21\\2019_U1_h21...   \n",
       "5                                                 NaN   \n",
       "6   dataset_clean\\EPI_ChipPress\\U1_h21\\2022_U1_h21...   \n",
       "7                                                 NaN   \n",
       "8   dataset_clean\\EPI_ChipPress\\U1_h21\\2023_U1_h21...   \n",
       "9                                                 NaN   \n",
       "10  dataset_clean\\EPI_ChipPress\\U1_h23\\2023_U1_h23...   \n",
       "11                                                NaN   \n",
       "12  dataset_clean\\EPI_ChipPress\\U1_h25\\2018_U1_h25...   \n",
       "13                                                NaN   \n",
       "14  dataset_clean\\EPI_ChipPress\\U1_h25\\2019_U1_h25...   \n",
       "15                                                NaN   \n",
       "16  dataset_clean\\EPI_ChipPress\\U1_h25\\2022_U1_h25...   \n",
       "17                                                NaN   \n",
       "18  dataset_clean\\EPI_ChipPress\\U1_h25\\2023_U1_h25...   \n",
       "19                                                NaN   \n",
       "\n",
       "                                                  src  \\\n",
       "0                                                 NaN   \n",
       "1   dataset_clean\\EPI_ChipPress\\U12_h31\\2019_U12_h...   \n",
       "2                                                 NaN   \n",
       "3   dataset_clean\\EPI_ChipPress\\U1_h21\\2019_U1_h21...   \n",
       "4                                                 NaN   \n",
       "5   dataset_clean\\EPI_ChipPress\\U1_h21\\2022_U1_h21...   \n",
       "6                                                 NaN   \n",
       "7   dataset_clean\\EPI_ChipPress\\U1_h21\\2023_U1_h21...   \n",
       "8                                                 NaN   \n",
       "9   dataset_clean\\EPI_ChipPress\\U1_h23\\2023_U1_h23...   \n",
       "10                                                NaN   \n",
       "11  dataset_clean\\EPI_ChipPress\\U1_h25\\2018_U1_h25...   \n",
       "12                                                NaN   \n",
       "13  dataset_clean\\EPI_ChipPress\\U1_h25\\2019_U1_h25...   \n",
       "14                                                NaN   \n",
       "15  dataset_clean\\EPI_ChipPress\\U1_h25\\2022_U1_h25...   \n",
       "16                                                NaN   \n",
       "17  dataset_clean\\EPI_ChipPress\\U1_h25\\2023_U1_h25...   \n",
       "18                                                NaN   \n",
       "19  dataset_clean\\EPI_ChipPress\\U1_h27\\2018_U1_h27...   \n",
       "\n",
       "                                                  dst  \n",
       "0                                                 NaN  \n",
       "1   D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...  \n",
       "2                                                 NaN  \n",
       "3   D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...  \n",
       "4                                                 NaN  \n",
       "5   D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...  \n",
       "6                                                 NaN  \n",
       "7   D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...  \n",
       "8                                                 NaN  \n",
       "9   D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...  \n",
       "10                                                NaN  \n",
       "11  D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...  \n",
       "12                                                NaN  \n",
       "13  D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...  \n",
       "14                                                NaN  \n",
       "15  D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...  \n",
       "16                                                NaN  \n",
       "17  D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...  \n",
       "18                                                NaN  \n",
       "19  D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total log rows: 2868\n",
      "Real run completed: files replaced and eligible measurement folders renamed.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "DATA_ROOT     = Path(\"dataset_clean\")  # relative to current working dir\n",
    "REGISTRY_CSV  = Path(\"dataset_clean/00meta_data/01removed_files_registry.csv\")\n",
    "OUTPUT_LOG    = Path(\"dataset_clean/00meta_data/empty_file_rewrite_log.csv\")\n",
    "\n",
    "TEST_MODE         = False     # process ONLY first eligible file; folder rename is DRY-RUN\n",
    "BACKUP_ORIGINALS  = True     # True -> move original to backup; False -> hard delete\n",
    "BACKUP_ROOT       = None     # None -> defaults to DATA_ROOT/../backup_empty_originals\n",
    "\n",
    "# If your dataset always uses one extension, set to \".csv.xz\" or \".csv\".\n",
    "# If None, the script will try both in this order: [\".csv.xz\", \".csv\"].\n",
    "PREFERRED_EXT     = None\n",
    "\n",
    "# ====== SCRIPT =========\n",
    "reg = pd.read_csv(REGISTRY_CSV)\n",
    "required_cols = {\"machine\", \"measurement\", \"year\", \"expected_data_file\"}\n",
    "missing = required_cols - set(reg.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Registry missing required columns: {missing}\")\n",
    "\n",
    "actions = []\n",
    "processed_any = False\n",
    "\n",
    "if BACKUP_ORIGINALS and BACKUP_ROOT is None:\n",
    "    BACKUP_ROOT = (DATA_ROOT.parent / \"backup_empty_originals\").resolve()\n",
    "\n",
    "# helper: return a viable path under DATA_ROOT, rebuilding from machine/measurement/year\n",
    "def build_expected_path(machine: str, measurement: str, year: str) -> tuple[Path, bool]:\n",
    "    \"\"\"\n",
    "    Rebuild the expected file path under DATA_ROOT regardless of what the registry contains.\n",
    "    Returns (path, is_xz) where is_xz indicates whether to write compressed replacement.\n",
    "    Tries PREFERRED_EXT first if provided, else tries .csv.xz then .csv.\n",
    "    \"\"\"\n",
    "    base = (DATA_ROOT / machine / measurement)\n",
    "    if PREFERRED_EXT:\n",
    "        p = base / f\"{year}_{measurement}{PREFERRED_EXT}\"\n",
    "        return p, (PREFERRED_EXT == \".csv.xz\")\n",
    "    # try .csv.xz then .csv\n",
    "    p1 = base / f\"{year}_{measurement}.csv.xz\"\n",
    "    if p1.exists():\n",
    "        return p1, True\n",
    "    p2 = base / f\"{year}_{measurement}.csv\"\n",
    "    return p2, False\n",
    "\n",
    "# Iterate rows\n",
    "for _, row in reg.iterrows():\n",
    "    machine     = str(row[\"machine\"])\n",
    "    measurement = str(row[\"measurement\"])\n",
    "    year        = str(row[\"year\"])\n",
    "\n",
    "    timestamp_col = \"WsDateTime\"\n",
    "    value_col     = measurement\n",
    "\n",
    "    # Always REBUILD the path under DATA_ROOT (ignoring absolute paths in registry)\n",
    "    expected_path, write_xz = build_expected_path(machine, measurement, year)\n",
    "\n",
    "    # Idempotency: skip if name already *_EMPTY\n",
    "    name = expected_path.name\n",
    "    already_empty_name = name.endswith(\"_EMPTY.csv\") or name.endswith(\"_EMPTY.csv.xz\")\n",
    "    if already_empty_name:\n",
    "        actions.append({\n",
    "            \"action\": \"skip_already_empty_naming\",\n",
    "            \"machine\": machine, \"measurement\": measurement, \"year\": year,\n",
    "            \"path\": str(expected_path)\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # If not found, also try the \"other\" extension (when PREFERRED_EXT is None)\n",
    "    if not expected_path.exists() and PREFERRED_EXT is None:\n",
    "        # flip ext\n",
    "        alt_xz = not write_xz\n",
    "        alt = expected_path.with_suffix(\".csv\" if alt_xz is False else \".xz\")\n",
    "        # ensure correct pair (.csv.xz requires two suffixes)\n",
    "        if str(alt).endswith(\".xz\"):\n",
    "            alt = expected_path.with_name(expected_path.stem + \".csv.xz\")\n",
    "        else:\n",
    "            alt = expected_path.with_name(expected_path.stem + \".csv\")\n",
    "        if alt.exists():\n",
    "            expected_path, write_xz = alt, alt.suffix.endswith(\"xz\")\n",
    "\n",
    "    if not expected_path.exists():\n",
    "        actions.append({\n",
    "            \"action\": \"missing_original\",\n",
    "            \"machine\": machine, \"measurement\": measurement, \"year\": year,\n",
    "            \"path\": str(expected_path)\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # Compute *_EMPTY filename\n",
    "    if expected_path.name.endswith(\".csv.xz\"):\n",
    "        target_path = expected_path.with_name(expected_path.name[:-7] + \"_EMPTY.csv.xz\")\n",
    "    elif expected_path.name.endswith(\".csv\"):\n",
    "        target_path = expected_path.with_name(expected_path.name[:-4] + \"_EMPTY.csv\")\n",
    "    else:\n",
    "        # fallback: append _EMPTY before final suffix\n",
    "        target_path = expected_path.with_name(expected_path.stem + \"_EMPTY\" + \"\".join(expected_path.suffixes))\n",
    "\n",
    "    # === TEST MODE: only the first eligible file; folder rename is DRY-RUN\n",
    "    if TEST_MODE and not processed_any:\n",
    "        # backup or delete\n",
    "        if BACKUP_ORIGINALS:\n",
    "            backup_dst = (BACKUP_ROOT / machine / measurement / expected_path.name).resolve()\n",
    "            backup_dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.move(str(expected_path), str(backup_dst))\n",
    "            actions.append({\n",
    "                \"action\": \"backup_original_dry_run\",\n",
    "                \"machine\": machine, \"measurement\": measurement, \"year\": year,\n",
    "                \"src\": str(expected_path), \"dst\": str(backup_dst)\n",
    "            })\n",
    "        else:\n",
    "            expected_path.unlink()\n",
    "            actions.append({\n",
    "                \"action\": \"delete_original_dry_run\",\n",
    "                \"machine\": machine, \"measurement\": measurement, \"year\": year,\n",
    "                \"path\": str(expected_path)\n",
    "            })\n",
    "\n",
    "        # write tiny *_EMPTY file (two cols, one row)\n",
    "        df = pd.DataFrame({timestamp_col: [f\"{year}-01-01 00:00:00\"], value_col: [0.0]})\n",
    "        target_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        if write_xz or target_path.suffix.endswith(\"xz\"):\n",
    "            df.to_csv(target_path, index=False, compression=\"xz\")\n",
    "        else:\n",
    "            df.to_csv(target_path, index=False)\n",
    "        actions.append({\n",
    "            \"action\": \"write_empty_file_dry_run\",\n",
    "            \"machine\": machine, \"measurement\": measurement, \"year\": year,\n",
    "            \"path\": str(target_path)\n",
    "        })\n",
    "\n",
    "        # folder rename DRY-RUN\n",
    "        meas_dir = target_path.parent\n",
    "        csv_like = list(meas_dir.glob(\"*.csv\")) + list(meas_dir.glob(\"*.csv.xz\"))\n",
    "        if csv_like and all(p.name.endswith(\"_EMPTY.csv\") or p.name.endswith(\"_EMPTY.csv.xz\") for p in csv_like):\n",
    "            if not meas_dir.name.endswith(\"_EMPTY\"):\n",
    "                actions.append({\n",
    "                    \"action\": \"rename_dir_dry_run\",\n",
    "                    \"src\": str(meas_dir),\n",
    "                    \"dst\": str(meas_dir.with_name(meas_dir.name + \"_EMPTY\"))\n",
    "                })\n",
    "\n",
    "        processed_any = True\n",
    "        break\n",
    "\n",
    "    # === REAL RUN (TEST_MODE=False): process all files\n",
    "    if not TEST_MODE:\n",
    "        if BACKUP_ORIGINALS:\n",
    "            backup_dst = (BACKUP_ROOT / machine / measurement / expected_path.name).resolve()\n",
    "            backup_dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.move(str(expected_path), str(backup_dst))\n",
    "            actions.append({\n",
    "                \"action\": \"backup_original\",\n",
    "                \"machine\": machine, \"measurement\": measurement, \"year\": year,\n",
    "                \"src\": str(expected_path), \"dst\": str(backup_dst)\n",
    "            })\n",
    "        else:\n",
    "            expected_path.unlink()\n",
    "            actions.append({\n",
    "                \"action\": \"delete_original\",\n",
    "                \"machine\": machine, \"measurement\": measurement, \"year\": year,\n",
    "                \"path\": str(expected_path)\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame({timestamp_col: [f\"{year}-01-01 00:00:00\"], value_col: [0.0]})\n",
    "        target_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        if write_xz or target_path.suffix.endswith(\"xz\"):\n",
    "            df.to_csv(target_path, index=False, compression=\"xz\")\n",
    "        else:\n",
    "            df.to_csv(target_path, index=False)\n",
    "        actions.append({\n",
    "            \"action\": \"write_empty_file\",\n",
    "            \"machine\": machine, \"measurement\": measurement, \"year\": year,\n",
    "            \"path\": str(target_path)\n",
    "        })\n",
    "\n",
    "# After processing: rename measurement folders if only *_EMPTY remain (real run only)\n",
    "if not TEST_MODE:\n",
    "    meas_dirs = set()\n",
    "    for _, row in reg.iterrows():\n",
    "        md = (DATA_ROOT / str(row[\"machine\"]) / str(row[\"measurement\"])).resolve()\n",
    "        meas_dirs.add(md)\n",
    "    for md in sorted(meas_dirs):\n",
    "        if not md.is_dir():\n",
    "            continue\n",
    "        csv_like = list(md.glob(\"*.csv\")) + list(md.glob(\"*.csv.xz\"))\n",
    "        if not csv_like:\n",
    "            continue\n",
    "        if all(p.name.endswith(\"_EMPTY.csv\") or p.name.endswith(\"_EMPTY.csv.xz\") for p in csv_like):\n",
    "            if not md.name.endswith(\"_EMPTY\"):\n",
    "                new_dir = md.with_name(md.name + \"_EMPTY\")\n",
    "                md.rename(new_dir)\n",
    "                actions.append({\"action\": \"rename_dir\", \"src\": str(md), \"dst\": str(new_dir)})\n",
    "\n",
    "# Log + preview\n",
    "log_df = pd.DataFrame(actions)\n",
    "OUTPUT_LOG.parent.mkdir(parents=True, exist_ok=True)\n",
    "log_df.to_csv(OUTPUT_LOG, index=False)\n",
    "\n",
    "display(log_df.head(20))\n",
    "print(f\"Total log rows: {len(log_df)}\")\n",
    "if TEST_MODE:\n",
    "    print(\"TEST_MODE=True → processed only the first eligible file and dry-ran the folder rename.\")\n",
    "else:\n",
    "    print(\"Real run completed: files replaced and eligible measurement folders renamed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02af8e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>machine</th>\n",
       "      <th>measurement</th>\n",
       "      <th>year</th>\n",
       "      <th>path</th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>backup_original</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U12_h31</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U12_h31\\2019_U12_h...</td>\n",
       "      <td>D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>backup_original</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h21</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h21\\2019_U1_h21...</td>\n",
       "      <td>D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>backup_original</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h21</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h21\\2022_U1_h21...</td>\n",
       "      <td>D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>backup_original</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h21</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h21\\2023_U1_h21...</td>\n",
       "      <td>D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>backup_original</td>\n",
       "      <td>EPI_ChipPress</td>\n",
       "      <td>U1_h23</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\U1_h23\\2023_U1_h23...</td>\n",
       "      <td>D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>backup_original</td>\n",
       "      <td>TEC_MV2400R</td>\n",
       "      <td>U1_DC</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_clean\\TEC_MV2400R\\U1_DC\\2024_U1_DC.csv.xz</td>\n",
       "      <td>D:\\EnergyDataset\\backup_empty_originals\\TEC_MV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>backup_original</td>\n",
       "      <td>TEC_MV2400R</td>\n",
       "      <td>U23_DC</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_clean\\TEC_MV2400R\\U23_DC\\2024_U23_DC.c...</td>\n",
       "      <td>D:\\EnergyDataset\\backup_empty_originals\\TEC_MV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>backup_original</td>\n",
       "      <td>TEC_MV2400R</td>\n",
       "      <td>U2_DC</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_clean\\TEC_MV2400R\\U2_DC\\2024_U2_DC.csv.xz</td>\n",
       "      <td>D:\\EnergyDataset\\backup_empty_originals\\TEC_MV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>backup_original</td>\n",
       "      <td>TEC_MV2400R</td>\n",
       "      <td>U31_DC</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_clean\\TEC_MV2400R\\U31_DC\\2024_U31_DC.c...</td>\n",
       "      <td>D:\\EnergyDataset\\backup_empty_originals\\TEC_MV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>backup_original</td>\n",
       "      <td>TEC_MV2400R</td>\n",
       "      <td>U3_DC</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_clean\\TEC_MV2400R\\U3_DC\\2024_U3_DC.csv.xz</td>\n",
       "      <td>D:\\EnergyDataset\\backup_empty_originals\\TEC_MV...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1351 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               action        machine measurement    year path  \\\n",
       "1     backup_original  EPI_ChipPress     U12_h31  2019.0  NaN   \n",
       "3     backup_original  EPI_ChipPress      U1_h21  2019.0  NaN   \n",
       "5     backup_original  EPI_ChipPress      U1_h21  2022.0  NaN   \n",
       "7     backup_original  EPI_ChipPress      U1_h21  2023.0  NaN   \n",
       "9     backup_original  EPI_ChipPress      U1_h23  2023.0  NaN   \n",
       "...               ...            ...         ...     ...  ...   \n",
       "2693  backup_original    TEC_MV2400R       U1_DC  2024.0  NaN   \n",
       "2695  backup_original    TEC_MV2400R      U23_DC  2024.0  NaN   \n",
       "2697  backup_original    TEC_MV2400R       U2_DC  2024.0  NaN   \n",
       "2699  backup_original    TEC_MV2400R      U31_DC  2024.0  NaN   \n",
       "2701  backup_original    TEC_MV2400R       U3_DC  2024.0  NaN   \n",
       "\n",
       "                                                    src  \\\n",
       "1     dataset_clean\\EPI_ChipPress\\U12_h31\\2019_U12_h...   \n",
       "3     dataset_clean\\EPI_ChipPress\\U1_h21\\2019_U1_h21...   \n",
       "5     dataset_clean\\EPI_ChipPress\\U1_h21\\2022_U1_h21...   \n",
       "7     dataset_clean\\EPI_ChipPress\\U1_h21\\2023_U1_h21...   \n",
       "9     dataset_clean\\EPI_ChipPress\\U1_h23\\2023_U1_h23...   \n",
       "...                                                 ...   \n",
       "2693  dataset_clean\\TEC_MV2400R\\U1_DC\\2024_U1_DC.csv.xz   \n",
       "2695  dataset_clean\\TEC_MV2400R\\U23_DC\\2024_U23_DC.c...   \n",
       "2697  dataset_clean\\TEC_MV2400R\\U2_DC\\2024_U2_DC.csv.xz   \n",
       "2699  dataset_clean\\TEC_MV2400R\\U31_DC\\2024_U31_DC.c...   \n",
       "2701  dataset_clean\\TEC_MV2400R\\U3_DC\\2024_U3_DC.csv.xz   \n",
       "\n",
       "                                                    dst  \n",
       "1     D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...  \n",
       "3     D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...  \n",
       "5     D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...  \n",
       "7     D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...  \n",
       "9     D:\\EnergyDataset\\backup_empty_originals\\EPI_Ch...  \n",
       "...                                                 ...  \n",
       "2693  D:\\EnergyDataset\\backup_empty_originals\\TEC_MV...  \n",
       "2695  D:\\EnergyDataset\\backup_empty_originals\\TEC_MV...  \n",
       "2697  D:\\EnergyDataset\\backup_empty_originals\\TEC_MV...  \n",
       "2699  D:\\EnergyDataset\\backup_empty_originals\\TEC_MV...  \n",
       "2701  D:\\EnergyDataset\\backup_empty_originals\\TEC_MV...  \n",
       "\n",
       "[1351 rows x 7 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"dataset_clean\\00meta_data\\empty_file_rewrite_log.csv\")\n",
    "df[df[\"action\"]==\"backup_original\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9892bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>n_total</th>\n",
       "      <th>n_nans</th>\n",
       "      <th>n_zeros</th>\n",
       "      <th>n_nans_start</th>\n",
       "      <th>n_nans_end</th>\n",
       "      <th>n_nans_middle</th>\n",
       "      <th>n_missing_gaps</th>\n",
       "      <th>missing_gap_total_sec</th>\n",
       "      <th>nan_1_step_count</th>\n",
       "      <th>nan_1_step_steps</th>\n",
       "      <th>nan_1_step_pct</th>\n",
       "      <th>nan_5s_30s_count</th>\n",
       "      <th>nan_5s_30s_steps</th>\n",
       "      <th>nan_5s_30s_pct</th>\n",
       "      <th>nan_30s_1m_count</th>\n",
       "      <th>nan_30s_1m_steps</th>\n",
       "      <th>nan_30s_1m_pct</th>\n",
       "      <th>nan_1m_15m_count</th>\n",
       "      <th>nan_1m_15m_steps</th>\n",
       "      <th>nan_1m_15m_pct</th>\n",
       "      <th>nan_15m_1h_count</th>\n",
       "      <th>nan_15m_1h_steps</th>\n",
       "      <th>nan_15m_1h_pct</th>\n",
       "      <th>nan_1h_24h_count</th>\n",
       "      <th>nan_1h_24h_steps</th>\n",
       "      <th>nan_1h_24h_pct</th>\n",
       "      <th>nan_1d_7d_count</th>\n",
       "      <th>nan_1d_7d_steps</th>\n",
       "      <th>nan_1d_7d_pct</th>\n",
       "      <th>nan_1w_1mo_count</th>\n",
       "      <th>nan_1w_1mo_steps</th>\n",
       "      <th>nan_1w_1mo_pct</th>\n",
       "      <th>nan_1mo_inf_count</th>\n",
       "      <th>nan_1mo_inf_steps</th>\n",
       "      <th>nan_1mo_inf_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset_clean\\EPI_ChipPress\\Freq\\2018_Freq.csv.xz</td>\n",
       "      <td>6307200</td>\n",
       "      <td>666965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>719</td>\n",
       "      <td>666246</td>\n",
       "      <td>320844</td>\n",
       "      <td>3334820</td>\n",
       "      <td>320689</td>\n",
       "      <td>1603445</td>\n",
       "      <td>48.08</td>\n",
       "      <td>79</td>\n",
       "      <td>1090</td>\n",
       "      <td>0.03</td>\n",
       "      <td>18</td>\n",
       "      <td>820</td>\n",
       "      <td>0.02</td>\n",
       "      <td>49</td>\n",
       "      <td>7665</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3</td>\n",
       "      <td>6595</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>18020</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1</td>\n",
       "      <td>198470</td>\n",
       "      <td>5.95</td>\n",
       "      <td>1</td>\n",
       "      <td>1498715</td>\n",
       "      <td>44.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path  n_total  n_nans  \\\n",
       "0  dataset_clean\\EPI_ChipPress\\Freq\\2018_Freq.csv.xz  6307200  666965   \n",
       "\n",
       "   n_zeros  n_nans_start  n_nans_end  n_nans_middle  n_missing_gaps  \\\n",
       "0        0             0         719         666246          320844   \n",
       "\n",
       "   missing_gap_total_sec  nan_1_step_count  nan_1_step_steps  nan_1_step_pct  \\\n",
       "0                3334820            320689           1603445           48.08   \n",
       "\n",
       "   nan_5s_30s_count  nan_5s_30s_steps  nan_5s_30s_pct  nan_30s_1m_count  \\\n",
       "0                79              1090            0.03                18   \n",
       "\n",
       "   nan_30s_1m_steps  nan_30s_1m_pct  nan_1m_15m_count  nan_1m_15m_steps  \\\n",
       "0               820            0.02                49              7665   \n",
       "\n",
       "   nan_1m_15m_pct  nan_15m_1h_count  nan_15m_1h_steps  nan_15m_1h_pct  \\\n",
       "0            0.23                 3              6595             0.2   \n",
       "\n",
       "   nan_1h_24h_count  nan_1h_24h_steps  nan_1h_24h_pct  nan_1d_7d_count  \\\n",
       "0                 4             18020            0.54                1   \n",
       "\n",
       "   nan_1d_7d_steps  nan_1d_7d_pct  nan_1w_1mo_count  nan_1w_1mo_steps  \\\n",
       "0           198470           5.95                 1           1498715   \n",
       "\n",
       "   nan_1w_1mo_pct  nan_1mo_inf_count  nan_1mo_inf_steps  nan_1mo_inf_pct  \n",
       "0           44.94                  0                  0              0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 **Summary for dataset_clean\\EPI_ChipPress\\Freq\\2018_Freq.csv.xz**\n",
      "\n",
      "- Total values: 6,307,200\n",
      "- Missing (NaN): 666,965 (10.57%)\n",
      "- Constant zeros: 0\n",
      "\n",
      "🔹 Missing structure:\n",
      "- Missing at start: 0\n",
      "- Missing at end:   719\n",
      "- Missing in middle: 666,246\n",
      "\n",
      "🔹 Gap statistics:\n",
      "- Number of gaps: 320,844\n",
      "- Total missing duration: 3,334,820 sec\n",
      "\n",
      "🔹 Gap size categories:\n",
      "- 1 step: 320689 gaps, 1,603,445 steps (48.08%)\n",
      "- 5s–30s: 79 gaps, 1,090 steps (0.03%)\n",
      "- 30s–1m: 18 gaps, 820 steps (0.02%)\n",
      "- 1m–15m: 49 gaps, 7,665 steps (0.23%)\n",
      "- 15m–1h: 3 gaps, 6,595 steps (0.20%)\n",
      "- 1h–24h: 4 gaps, 18,020 steps (0.54%)\n",
      "- 1d–7d:  1 gaps, 198,470 steps (5.95%)\n",
      "- 1w–1mo: 1 gaps, 1,498,715 steps (44.94%)\n",
      "- >1mo:   0 gaps, 0 steps (0.00%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(r\"validation_results\\EPI_ChipPress\\Freq\\2018_Freq_missing.csv\")\n",
    "with pd.option_context(\"display.max_columns\", None):\n",
    "    display(df2)\n",
    "\n",
    "row = df2.iloc[0]\n",
    "\n",
    "n_total   = row[\"n_total\"]\n",
    "n_nans    = row[\"n_nans\"]\n",
    "n_zeros   = row[\"n_zeros\"]\n",
    "\n",
    "pct_missing = (n_nans / n_total) * 100 if n_total else 0\n",
    "\n",
    "summary = f\"\"\"\n",
    "📊 **Summary for {row['file_path']}**\n",
    "\n",
    "- Total values: {n_total:,}\n",
    "- Missing (NaN): {n_nans:,} ({pct_missing:.2f}%)\n",
    "- Constant zeros: {n_zeros:,}\n",
    "\n",
    "🔹 Missing structure:\n",
    "- Missing at start: {row['n_nans_start']:,}\n",
    "- Missing at end:   {row['n_nans_end']:,}\n",
    "- Missing in middle: {row['n_nans_middle']:,}\n",
    "\n",
    "🔹 Gap statistics:\n",
    "- Number of gaps: {row['n_missing_gaps']:,}\n",
    "- Total missing duration: {row['missing_gap_total_sec']:,} sec\n",
    "\n",
    "🔹 Gap size categories:\n",
    "- 1 step: {row['nan_1_step_count']} gaps, {row['nan_1_step_steps']:,} steps ({row['nan_1_step_pct']:.2f}%)\n",
    "- 5s–30s: {row['nan_5s_30s_count']} gaps, {row['nan_5s_30s_steps']:,} steps ({row['nan_5s_30s_pct']:.2f}%)\n",
    "- 30s–1m: {row['nan_30s_1m_count']} gaps, {row['nan_30s_1m_steps']:,} steps ({row['nan_30s_1m_pct']:.2f}%)\n",
    "- 1m–15m: {row['nan_1m_15m_count']} gaps, {row['nan_1m_15m_steps']:,} steps ({row['nan_1m_15m_pct']:.2f}%)\n",
    "- 15m–1h: {row['nan_15m_1h_count']} gaps, {row['nan_15m_1h_steps']:,} steps ({row['nan_15m_1h_pct']:.2f}%)\n",
    "- 1h–24h: {row['nan_1h_24h_count']} gaps, {row['nan_1h_24h_steps']:,} steps ({row['nan_1h_24h_pct']:.2f}%)\n",
    "- 1d–7d:  {row['nan_1d_7d_count']} gaps, {row['nan_1d_7d_steps']:,} steps ({row['nan_1d_7d_pct']:.2f}%)\n",
    "- 1w–1mo: {row['nan_1w_1mo_count']} gaps, {row['nan_1w_1mo_steps']:,} steps ({row['nan_1w_1mo_pct']:.2f}%)\n",
    "- >1mo:   {row['nan_1mo_inf_count']} gaps, {row['nan_1mo_inf_steps']:,} steps ({row['nan_1mo_inf_pct']:.2f}%)\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
